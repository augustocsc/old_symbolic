/home/augusto/miniconda3/envs/sr/lib/python3.8/site-packages/trl/trainer/ppo_trainer.py:239: UserWarning: No dataset is provided. Make sure to set config.batch_size to the correct value before training.
  warnings.warn(
  0%|                                                                                               | 0/10 [00:00<?, ?it/s]avaliation.py:117: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  query_tensors = list(torch.tensor(query_tensors))
<lambdifygenerated-2>:2: RuntimeWarning: divide by zero encountered in reciprocal
  return log(x)**(-1.0)
<lambdifygenerated-3>:2: RuntimeWarning: overflow encountered in exp
  return x*(x*exp(x) + x)
<lambdifygenerated-3>:2: RuntimeWarning: overflow encountered in multiply
  return x*(x*exp(x) + x)
<lambdifygenerated-6>:2: RuntimeWarning: overflow encountered in exp
  return exp(x + 3)
<lambdifygenerated-8>:2: RuntimeWarning: overflow encountered in cosh
  return cosh(x)
<lambdifygenerated-10>:2: RuntimeWarning: overflow encountered in cosh
  return x*cosh(x)
<lambdifygenerated-10>:2: RuntimeWarning: overflow encountered in multiply
  return x*cosh(x)
<lambdifygenerated-12>:2: RuntimeWarning: overflow encountered in exp
  return x**2*exp(x)
<lambdifygenerated-12>:2: RuntimeWarning: overflow encountered in multiply
  return x**2*exp(x)
You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.
mean: 8.155621617333964e-05
top: 0.006204635836184025
 10%|████████▋                                                                              | 1/10 [00:16<02:25, 16.22s/it]<lambdifygenerated-22>:2: RuntimeWarning: overflow encountered in cosh
  return cosh(x + 1)
<lambdifygenerated-39>:2: RuntimeWarning: overflow encountered in cosh
  return cosh(x)**2
<lambdifygenerated-39>:2: RuntimeWarning: overflow encountered in square
  return cosh(x)**2
<lambdifygenerated-41>:2: RuntimeWarning: overflow encountered in exp
  return exp(x + 2)
<lambdifygenerated-42>:2: RuntimeWarning: invalid value encountered in arctanh
  return x*arctanh(4)
<lambdifygenerated-45>:2: RuntimeWarning: overflow encountered in cosh
  return cosh(x) + arcsin(x)
<lambdifygenerated-45>:2: RuntimeWarning: invalid value encountered in arcsin
  return cosh(x) + arcsin(x)
<lambdifygenerated-52>:2: RuntimeWarning: invalid value encountered in arccos
  return arccos(x + 3)
mean: 0.0005148627678863704
top: 0.027134176343679428
 20%|█████████████████▍                                                                     | 2/10 [00:31<02:05, 15.70s/it]<lambdifygenerated-60>:2: RuntimeWarning: divide by zero encountered in divide
  return x/log(x)
<lambdifygenerated-66>:2: RuntimeWarning: overflow encountered in sinh
  return -5*sinh(x)
<lambdifygenerated-66>:2: RuntimeWarning: overflow encountered in multiply
  return -5*sinh(x)
<lambdifygenerated-69>:2: RuntimeWarning: overflow encountered in exp
  return 5*x + exp(x)
<lambdifygenerated-76>:2: RuntimeWarning: overflow encountered in sinh
  return x + sinh(x)
<lambdifygenerated-79>:2: RuntimeWarning: overflow encountered in exp
  return x*exp(3*x)
<lambdifygenerated-79>:2: RuntimeWarning: overflow encountered in multiply
  return x*exp(3*x)
<lambdifygenerated-91>:2: RuntimeWarning: divide by zero encountered in arctanh
  return arctanh(sqrt(x))
<lambdifygenerated-91>:2: RuntimeWarning: invalid value encountered in arctanh
  return arctanh(sqrt(x))
<lambdifygenerated-99>:2: RuntimeWarning: overflow encountered in cosh
  return cosh(x + 2)
<lambdifygenerated-102>:2: RuntimeWarning: overflow encountered in cosh
  return cosh(x + 3)
mean: 0.0002716659219004214
top: 0.006204694509506226
 30%|██████████████████████████                                                             | 3/10 [00:51<01:59, 17.11s/it]
Traceback (most recent call last):
  File "avaliation.py", line 129, in <module>
    response = ppo_trainer.generate(query.to(device), **generation_kwargs)
  File "/home/augusto/miniconda3/envs/sr/lib/python3.8/site-packages/trl/trainer/ppo_trainer.py", line 457, in generate
    response = self.accelerator.unwrap_model(self.model).generate(
  File "/home/augusto/miniconda3/envs/sr/lib/python3.8/site-packages/trl/models/modeling_value_head.py", line 198, in generate
    return self.pretrained_model.generate(*args, **kwargs)
  File "/home/augusto/miniconda3/envs/sr/lib/python3.8/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/home/augusto/miniconda3/envs/sr/lib/python3.8/site-packages/transformers/generation/utils.py", line 1648, in generate
    return self.sample(
  File "/home/augusto/miniconda3/envs/sr/lib/python3.8/site-packages/transformers/generation/utils.py", line 2730, in sample
    outputs = self(
  File "/home/augusto/miniconda3/envs/sr/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/augusto/miniconda3/envs/sr/lib/python3.8/site-packages/transformers/models/gpt2/modeling_gpt2.py", line 1076, in forward
    transformer_outputs = self.transformer(
  File "/home/augusto/miniconda3/envs/sr/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/augusto/miniconda3/envs/sr/lib/python3.8/site-packages/transformers/models/gpt2/modeling_gpt2.py", line 900, in forward
    outputs = block(
  File "/home/augusto/miniconda3/envs/sr/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/augusto/miniconda3/envs/sr/lib/python3.8/site-packages/transformers/models/gpt2/modeling_gpt2.py", line 390, in forward
    attn_outputs = self.attn(
  File "/home/augusto/miniconda3/envs/sr/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/augusto/miniconda3/envs/sr/lib/python3.8/site-packages/transformers/models/gpt2/modeling_gpt2.py", line 331, in forward
    attn_output, attn_weights = self._attn(query, key, value, attention_mask, head_mask)
  File "/home/augusto/miniconda3/envs/sr/lib/python3.8/site-packages/transformers/models/gpt2/modeling_gpt2.py", line 183, in _attn
    attn_weights = torch.matmul(query, key.transpose(-1, -2))
KeyboardInterrupt