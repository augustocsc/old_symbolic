/home/augusto/miniconda3/envs/sr/lib/python3.8/site-packages/trl/trainer/ppo_trainer.py:239: UserWarning: No dataset is provided. Make sure to set config.batch_size to the correct value before training.
  warnings.warn(
avaliation.py:112: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  query_tensors = list(torch.tensor(query_tensors))
Index(['type', 'name', 'expression'], dtype='object')
/home/augusto/miniconda3/envs/sr/lib/python3.8/site-packages/sklearn/metrics/_regression.py:481: RuntimeWarning: invalid value encountered in sqrt
  output_errors = np.sqrt(output_errors)
<lambdifygenerated-15>:2: RuntimeWarning: overflow encountered in cosh
  return x**2 + x*cosh(x)
<lambdifygenerated-28>:2: RuntimeWarning: overflow encountered in exp
  return x + exp(x) - arctanh(x)
<lambdifygenerated-28>:2: RuntimeWarning: invalid value encountered in arctanh
  return x + exp(x) - arctanh(x)
<lambdifygenerated-32>:2: RuntimeWarning: overflow encountered in exp
  return exp(2*x + 5)
<lambdifygenerated-38>:2: RuntimeWarning: invalid value encountered in log
  return x*arctan(x) - log(cos(x)) + sin(x)
<lambdifygenerated-40>:2: RuntimeWarning: divide by zero encountered in log
  return x*log(tanh(x) - 1) - x - log(tanh(x) + 1)
<lambdifygenerated-40>:2: RuntimeWarning: invalid value encountered in log
  return x*log(tanh(x) - 1) - x - log(tanh(x) + 1)
<lambdifygenerated-45>:2: RuntimeWarning: invalid value encountered in arcsin
  return x + arcsin(x)
/home/augusto/miniconda3/envs/sr/lib/python3.8/site-packages/sklearn/metrics/_regression.py:481: RuntimeWarning: invalid value encountered in sqrt
  output_errors = np.sqrt(output_errors)
<lambdifygenerated-54>:2: RuntimeWarning: overflow encountered in exp
  return exp(x) + arcsin(x)
<lambdifygenerated-54>:2: RuntimeWarning: invalid value encountered in arcsin
  return exp(x) + arcsin(x)
<lambdifygenerated-68>:2: RuntimeWarning: overflow encountered in exp
  return x**2*exp(x) + x
<lambdifygenerated-68>:2: RuntimeWarning: overflow encountered in multiply
  return x**2*exp(x) + x
<lambdifygenerated-69>:2: RuntimeWarning: invalid value encountered in arccos
  return (1/2)*x**2*arccos(2)
/home/augusto/miniconda3/envs/sr/lib/python3.8/site-packages/sklearn/metrics/_regression.py:481: RuntimeWarning: invalid value encountered in sqrt
  output_errors = np.sqrt(output_errors)
<lambdifygenerated-76>:2: RuntimeWarning: overflow encountered in exp
  return x*exp(x) - x
<lambdifygenerated-77>:2: RuntimeWarning: overflow encountered in cosh
  return 4*sin(x) + cosh(x)
<lambdifygenerated-78>:2: RuntimeWarning: invalid value encountered in arccos
  return x/arccos(2)
<lambdifygenerated-79>:2: RuntimeWarning: invalid value encountered in arctanh
  return log(x)*arctanh(x**2)
<lambdifygenerated-82>:2: RuntimeWarning: invalid value encountered in arctanh
  return x**2*log(x) - x*arctanh(x) + x + log(x)
<lambdifygenerated-83>:2: RuntimeWarning: invalid value encountered in arcsin
  return x**2 + x - arcsin(x)
<lambdifygenerated-85>:2: RuntimeWarning: invalid value encountered in arctanh
  return x + x*arctanh(5)
<lambdifygenerated-88>:2: RuntimeWarning: invalid value encountered in arccos
  return x*(x + arccos(x))
<lambdifygenerated-93>:2: RuntimeWarning: overflow encountered in cosh
  return x*(cosh(x) + 4)
/home/augusto/miniconda3/envs/sr/lib/python3.8/site-packages/sklearn/metrics/_regression.py:481: RuntimeWarning: invalid value encountered in sqrt
  output_errors = np.sqrt(output_errors)
<lambdifygenerated-96>:2: RuntimeWarning: overflow encountered in exp
  return exp(x + 3)
<lambdifygenerated-99>:2: RuntimeWarning: overflow encountered in exp
  return -4*x*exp(x)
<lambdifygenerated-99>:2: RuntimeWarning: overflow encountered in multiply
  return -4*x*exp(x)
<lambdifygenerated-101>:2: RuntimeWarning: overflow encountered in sinh
  return x + 2*sinh(x)
<lambdifygenerated-122>:2: RuntimeWarning: overflow encountered in exp
  return -x - exp(x)
<lambdifygenerated-125>:2: RuntimeWarning: overflow encountered in exp
  return (1/2)*x**2 - 3*x*exp(x) - exp(x)
<lambdifygenerated-125>:2: RuntimeWarning: overflow encountered in multiply
  return (1/2)*x**2 - 3*x*exp(x) - exp(x)
x**5/5 + x**2/2 0.0000
2*x**2 + x 0.0007
None 0.0000
None 0.0000
x/(x + 6) 0.3395
cos(1)/x 0.3393
-2*x + cos(x)/x 0.2045
None 0.0000
6*x**5 0.0000
None 0.0000
2*x**4 0.0000
4*x**3/3 0.0000
None 0.0000
-x**3/3 - x**2/2 + x 0.0000
x/(x + 3) 0.3395
None 0.0000
x**2*sinh(1)/2 0.0023
x*sin(4) + 2*x 0.5748
5*sqrt(2)*x**(3/2)/9 0.0507
-x**6/16 + x**2*log(x**2)/2 0.0000
x**2 + x*cosh(x) 0.0000
2*x*(x + 3) 0.0007
(3 - x)/x 0.3391
None 0.0000
None 0.0000
None 0.0000
None 0.0000
x + 2 0.5069
None 0.0000
x**2*sin(5)/5 0.0069
None 0.0000
x**2/2 + sin(x)*cos(x)/5 0.0027
sin(x**2)/2 0.3393
None 0.0000
None 0.0000
-1/x 0.3393
sin(2*x + 4) 0.3393
0 0.0000
None 0.0000
2*(2*x + 1)/x 0.3400
sqrt(x) + 4 0.3444
(2*x**2 + x)/x 0.9965
x + exp(x) - atanh(x) 0.0000
-x**2 0.0014
None 0.0000
None 0.0000
x*(2*x + 4) + x 0.0007
x - 1/x**2 0.5061
None 0.0000
exp(2*x + 5) 0.0000
None 0.0000
x + 2/x 0.5061
-2*x**(7/2)/7 0.0000
-4*x**2 + 2*x 0.0003
None 0.0000
5*x*(x - 4) 0.0003
x*(x + 4) + 2*x 0.0013
x*atan(x) - log(cos(x)) + sin(x) 0.0000
None 0.0000
x - cos(x) 0.5061
x*log(tanh(x) - 1) - x - log(tanh(x) + 1) 0.0000
log(2*x**2) 0.3416
None 0.0000
None 0.0000
None 0.0000
x**2/2 + 5*log(x) 0.0027
0 0.0000
x**2 + 28*x 0.0013
x + asin(x) 0.0000
x + sin(x) + 1 0.5065
x*(x + 1/x) 0.0014
x**4 + x + 1 0.0000
None 0.0000
x**4/4 - x**3/3 + x**2/2 0.0000
None 0.0000
4*x**3/3 - x**2 0.0000
3*sin(x/4) 0.3393
-2*x + log(x)**2*tan(x) 0.1927
None 0.0000
sin(x) 0.3393
exp(x) + asin(x) 0.0000
x**2 + 4*x 0.0014
x**6/3 + 5*x**3 + x**2/2 0.0000
x/(x**3 + x) 0.3393
2*x + tan(5) 0.9889
sqrt(x) + x + 3 0.5171
x**4/12 + x**3/3 0.0000
1/(x**2 + x) 0.3393
None 0.0000
None 0.0000
None 0.0000
x + log(x)**2 0.5223
49*x**3/36 0.0000
None 0.0000
x**2 + 5*x 0.0014
-6*x**2 + 2*x 0.0002
None 0.0000
sqrt(3)*x**(5/2)/3 0.0001
sqrt(2*x + 3) 0.3455
x**2*exp(x) + x 0.0000
x**2*acos(2)/2 0.0000
None 0.0000
7*x/2 - 8*atan(3*x/2) 0.4109
None 0.0000
4*x**(7/2)/7 + x**6/2 0.0000
6*sin(x) 0.3394
None 0.0000
x**2*(x**3 + x)**2 0.0000
None 0.0000
None 0.0000
None 0.0000
x**3/(3*log(2)) 0.0000
None 0.0000
2*x - cos(x) 0.9947
None 0.0000
x*exp(x) - x 0.0000
4*sin(x) + cosh(x) 0.0000
x/acos(2) 0.0000
None 0.0000
log(x)*atanh(x**2) 0.0000
x*sin(x + 2) 0.3137
1/(x + 3) 0.3393
x**2*log(x) - x*atanh(x) + x + log(x) 0.0000
x**2 + x - asin(x) 0.0000
5*x**3 + x 0.0000
x + x*atanh(5) 0.0000
x**2*tan(3)/12 0.0859
sqrt(2*x + 3) 0.3455
None 0.0000
x*(x + acos(x)) 0.0000
None 0.0000
None 0.0000
3*x**2 - x 0.0005
(x**2 + x)**4 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
x**2/2 + 8*log(x) 0.0027
2*x**(5/2)/5 + x**4/2 0.0000
x*(cosh(x) + 4) 0.0000
None 0.0000
x*(x**5 + x) 0.0000
None 0.0000
3/(5*x) 0.3393
exp(x + 3) 0.0000
4*x**2 + x 0.0003
None 0.0000
x**6 - x**2/4 0.0000
None 0.0000
-4*x*exp(x) 0.0000
124/x**3 0.3393
x + 2*sinh(x) 0.0000
5 - x 0.2557
None 0.0000
2*x**2 - sin(x) 0.0007
None 0.0000
x*(x + 3) 0.0014
None 0.0000
x**2/2 0.0027
x**4/4 + 4*x**3/3 0.0000
None 0.0000
None 0.0000
3*x**2/2 0.0009
x**2/(4*cos(4)) 0.0035
2*sin(x) 0.3393
None 0.0000
2*x - sin(x) 0.9945
None 0.0000
x**6/6 + x**3/3 0.0000
None 0.0000
None 0.0000
x**2*log(4)/2 0.0020
x**3/3 - x**2 0.0000
None 0.0000
61*x**2 0.0000
x**8 + 3*x**2/2 0.0000
4*x + 4*log(x) 0.3359
-x - log(sqrt(x) + 1) 0.2549
4 - x**2 0.0014
x**2/2 + x*tan(1) 0.0027
None 0.0000
x**4/9 0.0000
None 0.0000
8*x**2 + x 0.0002
-x - exp(x) 0.0000
x**4/4 + 2*x 0.0000
tan(3*x + 3) 0.3391
x**2/2 - 3*x*exp(x) - exp(x) 0.0000
None 0.0000
x 0.5061
1/(2*x**2 + x) 0.3393
x**5/5 + 2*x 0.0000
None 0.0000
None 0.0000
5*x*log(x) 0.0324
None 0.0000
cosh(2*x + 1) 0.0000
x**2*sinh(x) 0.0000
None 0.0000
2*x + sin(x) 0.9948
2*x 0.9948
5*x**2/2 + 6*x 0.0005
1/(2*x) 0.3393
None 0.0000
-cos(x + 2) 0.3393
x**2*log(x) + x 0.0002
x**4/4 + x**2/2 + 3*x 0.0000
-x**3*sin(x) + x 0.0000
None 0.0000
None 0.0000
cos(x)/x 0.3393
x**2/2 + (3*x + 2)**(3/2)/3 0.0024
acos(3*x) 0.0000
2/(3*x) 0.3393
cos(4*x + 1) 0.3393
None 0.0000
2*(x + 2)**3 0.0000
4*x**5/5 + x**2/2 0.0000
x**3/log(x**2) 0.0000
sqrt(3)/(2*x + 5) 0.3393
x*atan(x) + log(x + 1) - atan(x) 0.7063
None 0.0000
None 0.0000
tan(x + 3) 0.3391
-x/5 0.3183
2*x*atanh(4) 0.0000
-x + sin(x)*cos(x) 0.2552
x**2*(log(x) + 1) 0.0002
None 0.0000
5*x**2/2 0.0005
x/(x + 3) 0.3395
x**3*sin(1)/3 0.0000
None 0.0000
None 0.0000
exp(2*x + 1) 0.0000
None 0.0000
None 0.0000
4*x**2 + 3*x 0.0003
None 0.0000
2*x**2 + 5 0.0007
tanh(2*x + 1)/2 0.3394
None 0.0000
x*atanh(x) - x 0.0000
x*(x + 5) 0.0014
x**3/3 + x**2/2 0.0000
x**3 + x**2 0.0000
4*x/3 0.6053
-2*log(x + 2) - 2*log(cos(x)) 0.0000
3 - 3*x 0.1707
None 0.0000
None 0.0000
x + sin(x) 0.5061
2*x*log(2*x**3) 0.0259
5*x/(x + 1) 0.3402
sin(3*x + 1) 0.3393
<lambdifygenerated-130>:2: RuntimeWarning: overflow encountered in cosh
  return cosh(2*x + 1)
<lambdifygenerated-131>:2: RuntimeWarning: overflow encountered in sinh
  return x**2*sinh(x)
<lambdifygenerated-131>:2: RuntimeWarning: overflow encountered in multiply
  return x**2*sinh(x)
<lambdifygenerated-142>:2: RuntimeWarning: invalid value encountered in arccos
  return arccos(3*x)
<lambdifygenerated-152>:2: RuntimeWarning: invalid value encountered in arctanh
  return 2*x*arctanh(4)
<lambdifygenerated-158>:2: RuntimeWarning: overflow encountered in exp
  return exp(2*x + 1)
<lambdifygenerated-162>:2: RuntimeWarning: invalid value encountered in arctanh
  return x*arctanh(x) - x
<lambdifygenerated-167>:2: RuntimeWarning: invalid value encountered in log
  return -2*log(x + 2) - 2*log(cos(x))
You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.
avaliation.py:112: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  query_tensors = list(torch.tensor(query_tensors))
mean: 0.10527157038450241
top: 0.33945873379707336
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
x**3/3 - cos(x) 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
acosh(x + 4) 0.3405
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
4*x**5/5 + x**2/2 0.0000
None 0.0000
x**4/4 + x 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
-x**2 + x*acos(x) + sqrt(1 - x**2) 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
x**2/2 + x*tan(4) 0.0027
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
x**2/(4*(2*x + 5)) 0.3538
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
x*(x**2 - 1) 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
2*x + acos(x) 0.0000
None 0.0000
None 0.0000
None 0.0000
x**8/2 + 1/3 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
x**2*exp(3)/2 0.0001
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
x*(2*x + 3) 0.0007
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
x*(-2*x**2 + x) 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
1 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
0 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
x**2*cos(1)/2 0.0050
None 0.0000
0 0.0000
x**2/(x + 5) 0.5042
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
1/15 0.0000
None 0.0000
<lambdifygenerated-177>:2: RuntimeWarning: invalid value encountered in arccos
  return -x**2 + x*arccos(x) + sqrt(1 - x**2)
<lambdifygenerated-177>:2: RuntimeWarning: invalid value encountered in sqrt
  return -x**2 + x*arccos(x) + sqrt(1 - x**2)
<lambdifygenerated-181>:2: RuntimeWarning: invalid value encountered in arccos
  return 2*x + arccos(x)
avaliation.py:112: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  query_tensors = list(torch.tensor(query_tensors))
mean: 0.004715197719633579
top: 4.887338036496658e-06
<lambdifygenerated-192>:2: RuntimeWarning: overflow encountered in exp
  return (1/2)*x**2 + (x - 1)*exp(x)
/home/augusto/miniconda3/envs/sr/lib/python3.8/site-packages/sklearn/metrics/_regression.py:481: RuntimeWarning: invalid value encountered in sqrt
  output_errors = np.sqrt(output_errors)
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
x**2/2 + (x - 1)*exp(x) 0.0000
x + 6*log(x) 0.5212
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
x 0.5061
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
5*x**4 + x 0.0000
None 0.0000
x**7/7 + x**2/2 0.0000
2*cos(x)/x 0.3393
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
x**2/2 0.0027
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
x**2 0.0014
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
sqrt(2)*x**2 0.0010
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
2*x - 1/4 0.9943
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
x**2/2 0.0027
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
3/2 - sin(x) 0.3395
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
x*(-x**2 + x + 4) 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
5*x**2/2 0.0005
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
3*x**3 + x 0.0000
None 0.0000
None 0.0000
None 0.0000
x**2 + 5*x 0.0014
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
x**3/3 + x**2/2 + 1/5 0.0000
None 0.0000
3*x**5/5 + 9*x**2 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
avaliation.py:112: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  query_tensors = list(torch.tensor(query_tensors))
mean: 0.010586298070847988
top: 0.5211899280548096
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
x**5/5 + 2*x**2 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
tan(x)**22 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
x**4/4 + x**2/2 0.0000
None 0.0000
None 0.0000
None 0.0000
x**10/12 + 2*x 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
x**3/3 + x*log(2) 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
1/6 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
avaliation.py:112: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  query_tensors = list(torch.tensor(query_tensors))
mean: 1.9120378169645846e-08
top: 0.0
<lambdifygenerated-221>:2: RuntimeWarning: overflow encountered in exp
  return (1/2)*x**2 + exp(2*x)
None 0.0000
1/2 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
x**2 + x*(x + 1) 0.0007
None 0.0000
None 0.0000
x**2/2 0.0027
None 0.0000
None 0.0000
None 0.0000
x**2*(x**3/3 + sin(x)*cos(x) - sin(x))*sin(x)*cos(x)/3 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
1 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
x**2/2 + exp(2*x) 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
x**2/2 + 1/16 0.0027
None 0.0000
None 0.0000
x**4/4 + 2*x**3/3 + 5*x**2/2 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
2*x**(5/2)/5 + x 0.0001
None 0.0000
None 0.0000
None 0.0000
1/2 - 3*cos(x) 0.3394
None 0.0000
None 0.0000
mean: 0.001350176171399653
top: 0.0
avaliation.py:112: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  query_tensors = list(torch.tensor(query_tensors))
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
2*x**3/3 + x**2/2 - x 0.0000
None 0.0000
None 0.0000
None 0.0000
x**2/2 + 1/4 0.0027
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
2*x**3/3 + x**2/2 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
x**2/2 + 1/15 0.0027
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
x**4/3 + x**2/4 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
5*x + 5/4 0.2556
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
x**2/2 + 1/5 0.0027
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
sqrt(3)*(x**3)**(1/4)/3 0.3524
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
x**4/4 0.0000
None 0.0000
None 0.0000
3*x**7 + x**2/2 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
x**2/2 + log(8)/17 0.0027
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
avaliation.py:112: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  query_tensors = list(torch.tensor(query_tensors))
mean: 0.0024176789447665215
top: 2.441504648231785e-06
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
5*x**2/4 0.0011
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
2*x**3/3 + 131*x**2/2 - 5*x 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
x**5/5 + x**2/2 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
None 0.0000
avaliation.py:112: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  query_tensors = list(torch.tensor(query_tensors))
mean: 4.254754912835779e-06
top: 0.0
Traceback (most recent call last):
  File "avaliation.py", line 124, in <module>
    response = ppo_trainer.generate(query.to(device), **generation_kwargs)
  File "/home/augusto/miniconda3/envs/sr/lib/python3.8/site-packages/trl/trainer/ppo_trainer.py", line 457, in generate
    response = self.accelerator.unwrap_model(self.model).generate(
  File "/home/augusto/miniconda3/envs/sr/lib/python3.8/site-packages/trl/models/modeling_value_head.py", line 198, in generate
    return self.pretrained_model.generate(*args, **kwargs)
  File "/home/augusto/miniconda3/envs/sr/lib/python3.8/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/home/augusto/miniconda3/envs/sr/lib/python3.8/site-packages/transformers/generation/utils.py", line 1648, in generate
    return self.sample(
  File "/home/augusto/miniconda3/envs/sr/lib/python3.8/site-packages/transformers/generation/utils.py", line 2730, in sample
    outputs = self(
  File "/home/augusto/miniconda3/envs/sr/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/augusto/miniconda3/envs/sr/lib/python3.8/site-packages/transformers/models/gpt2/modeling_gpt2.py", line 1076, in forward
    transformer_outputs = self.transformer(
  File "/home/augusto/miniconda3/envs/sr/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/augusto/miniconda3/envs/sr/lib/python3.8/site-packages/transformers/models/gpt2/modeling_gpt2.py", line 900, in forward
    outputs = block(
  File "/home/augusto/miniconda3/envs/sr/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/augusto/miniconda3/envs/sr/lib/python3.8/site-packages/transformers/models/gpt2/modeling_gpt2.py", line 390, in forward
    attn_outputs = self.attn(
  File "/home/augusto/miniconda3/envs/sr/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/augusto/miniconda3/envs/sr/lib/python3.8/site-packages/transformers/models/gpt2/modeling_gpt2.py", line 312, in forward
    query, key, value = self.c_attn(hidden_states).split(self.split_size, dim=2)
  File "/home/augusto/miniconda3/envs/sr/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/augusto/miniconda3/envs/sr/lib/python3.8/site-packages/transformers/pytorch_utils.py", line 106, in forward
    x = torch.addmm(self.bias, x.view(-1, x.size(-1)), self.weight)
KeyboardInterrupt